# 口型同步 LipSync

## 1. 概述 Overview

口型同步(LipSync)技术通过分析梅尔倒谱系数(MFCC)数据,解析音频中的元音信息(日语或汉语中的a,i,u,e,o),并且将其反应到璃奈板的口型上.在用户层面,该技术可以检测用户的麦克风输入来实时控制璃奈板的表情来模拟说话的效果.在开发者层面,该技术可以辅助编写时间轴文件,提升开发效率.

>在声音处理领域中,**梅尔频率倒谱**(Mel-Frequency Cepstrum)是基于声音频率的非线性[梅尔刻度](https://zh.wikipedia.org/wiki/梅尔刻度)(mel scale)的[对数](https://zh.wikipedia.org/wiki/對數)能量频谱的线性变换.
>
>**梅尔频率倒谱系数** (**Mel-Frequency Cepstral Coefficients,MFCCs**)就是组成梅尔频率倒谱的系数.它衍生自音讯片段的[倒频谱](https://zh.wikipedia.org/wiki/倒頻譜)(cepstrum).倒谱和梅尔频率倒谱的区别在于,梅尔频率倒谱的频带划分是在[梅尔刻度](https://zh.wikipedia.org/wiki/梅尔刻度)上等距划分的,它比用于正常的对数[倒频谱](https://zh.wikipedia.org/wiki/倒頻譜)中的线性间隔的频带更能近似人类的听觉系统. 这样的非线性表示,可以在多个领域中使声音信号有更好的表示.例如在[音讯压缩](https://zh.wikipedia.org/wiki/音訊壓縮)中.
>
>梅尔频率倒谱系数(MFCC)广泛被应用于[语音识别](https://zh.wikipedia.org/wiki/語音識別)的功能.他们由Davis和Mermelstein在1980年代提出,并在其后持续是最先进的技术之一.在MFCC之前,线性预测系数(LPCS)和线性预测倒谱系数(LPCCs)是自动语音识别的的主流方法.
>
>
>MFCC通常有以下之过程:
>
>1. 将一段语音信号分解为多个[讯框](https://zh.wikipedia.org/wiki/訊框).
>2. 将语音信号[预强化](https://zh.wikipedia.org/w/index.php?title=預強化&action=edit&redlink=1),通过一个[高通滤波器](https://zh.wikipedia.org/wiki/高通濾波器).
>3. 进行[傅立叶变换](https://zh.wikipedia.org/wiki/傅立叶变换),将信号变换至频域.
>4. 将每个[讯框](https://zh.wikipedia.org/wiki/訊框)获得的频谱通过梅尔滤波器(三角重叠窗口),得到[梅尔刻度](https://zh.wikipedia.org/wiki/梅尔刻度).
>5. 在每个梅尔刻度上提取[对数](https://zh.wikipedia.org/wiki/對數)能量.
>6. 对上面获得的结果进行[离散余弦变换](https://zh.wikipedia.org/wiki/離散餘弦轉換),变换到[倒频谱](https://zh.wikipedia.org/wiki/倒頻譜)域.
>7. MFCC就是这个[倒频谱](https://zh.wikipedia.org/wiki/倒頻譜)图的幅度(amplitudes).一般使用12个系数,与讯框能量叠加得13维的系数.
>
>from [梅尔频率倒谱系数 - 维基百科,自由的百科全书](https://zh.wikipedia.org/wiki/梅尔频率倒谱系数)

## 2. 原理 Theory

以下内容摘录改写自项目[huailiang/LipSync: LipSync for Unity3D 根据语音生成口型动画 支持fmod](https://github.com/huailiang/LipSync?tab=readme-ov-file)的Readme.主流的基于MFCC的口型同步算法基本都符合该原理.由于本项目采用的方式是实时匹配,因而删去了烘培的相关原理.

### 2.1 从AudioSource处获取语音数据

从AudioSource处获取是实时匹配时采用的方法.AudioSource本身提供了一个GetOutputData函数,可以获取当前正在播放的语音数据段,过程中也包含了分帧与窗口化的步骤.

### 2.2 剔除无声帧

从信号处理的角度上说,这一步是一种时域分析方法.对数据帧中的所有值进行求和,如果结果大于用户预设的一个阈值(也就是AmplitudeThreshold),那么就认为这一帧是没有声音的,不对它进行后续处理.这可以节省不必要的分析过程.如果适当调高阈值,一定程度上可以降噪.

### 2.3 获取语音数据的频域信息

频域信息指的就是频谱,这对于语音识别来说是非常重要的信息.实时匹配时,AudioSource的`GetSpecturmData`函数带来了极大的帮助,这个函数本身可以高效地获取当前播放的语音数据频谱.

### 2.4 提取共振峰

人在发声时,肺部收缩送出一股直流空气,经器官流至喉头声门处(即声带),使声带产生振动,并且具有一定的振动周期,从而带动原先的空气发生振动,这可以称为气流的激励过程.之后,空气经过声带以上的主声道部分(包括咽喉,口腔)以及鼻道(包括小舌,鼻腔),不同的发音会使声道的肌肉处在不同的部位,这形成了各种语音的不同音色,这可以称为气流在声道的冲激响应过程.

对于语音识别来说,重要的部分是第二个过程,因为"口型"就是声道形状的一部分.而这一冲激响应过程,在频谱上的表现为若干个凸起的包络峰.这些包络峰出现的频率,就被称为"共振峰频率",简称为"共振峰". 一般来说,通过求得一段语音数据的第一,第二共振峰,就可以非常精确地得知这段语音的"元音"是什么.只求第一共振峰,也可以知道大致结果.LipSync的核心步骤正是如此.提取共振峰的方法是,在前一步骤中获取的频谱上求出局部最大值的最大值.

### 2.5 把共振峰映射为元音特征值,进行平滑过渡处理,再赋予到目标对象上

主要是一些映射操作与平滑过渡处理.

## 3. 参考 References

本项目中的口型同步模块参考了项目[hecomi/uLipSync: MFCC-based LipSync plug-in for Unity using Job System and Burst Compiler](https://github.com/hecomi/uLipSync),该项目遵循MIT协议开源.对其中部分代码进行了改写以更契合本项目的需求:

- 删去了本项目无需依赖的部分
- 类名,函数名,变量名调整
- 一些语法上的调整

## 4. 命名空间 Namespace

本项目中所有涉及口型同步的模块均使用`RinaLipSync`命名空间.

## 5. 工具 Tools

该部分为实现口型同步算法提供了一系列工具类型,根路径位于`Assets/Scripts/Tools/RinaLipSync`.

### 5.1 算法 Algorithm

静态类`Algorithm` 提供了一系列语音信号分析和处理的算法以完成语音信号的MFCC特征提取;音频信号处理(如降噪,归一化,频谱分析)等工作.

#### 5.1.1 最大值计算`GetMaxValue`

计算数组中绝对值的最大值,用于快速找到音频信号的最大振幅.

#### 5.1.2 RMS音量计算`GetRMSVolume`

计算音频信号的均方根(RMS)音量,反映信号的总体强度.

#### 5.1.3 循环缓冲区复制`CopyRingBuffer`

实现循环缓冲区的数据复制功能,用于处理循环队列或滑动窗口.

> **圆形缓冲区**(circular buffer),也称作**圆形队列**(circular queue),**循环缓冲区**(cyclic buffer),**环形缓冲区**(ring buffer),是一种用于表示一个固定尺寸,头尾相连的[缓冲区](https://zh.wikipedia.org/wiki/缓冲区)的数据结构,适合缓存[数据流](https://zh.wikipedia.org/wiki/数据流).
>
> 圆形缓冲区的一个有用特性是: 当一个数据元素被用掉后,其余数据元素不需要移动其存储位置.相反,一个非圆形缓冲区(例如一个普通的队列)在用掉一个数据元素后,其余数据元素需要向前搬移.换句话说,圆形缓冲区适合实现[先进先出](https://zh.wikipedia.org/wiki/先進先出演算法)缓冲区,而非圆形缓冲区适合[后进先出](https://zh.wikipedia.org/wiki/後進先出)缓冲区.
>
> 圆形缓冲区适合于事先明确了缓冲区的最大容量的情形.扩展一个圆形缓冲区的容量,需要搬移其中的数据.因此一个缓冲区如果需要经常调整其容量,用链表实现更为合适.
>
> 写操作覆盖圆形缓冲区中未被处理的数据在某些情况下是允许的.特别是在多媒体处理时.例如,音频的生产者可以覆盖掉[声卡](https://zh.wikipedia.org/wiki/声卡)尚未来得及处理的音频数据.
>
> 具体参见 [环形缓冲器 - 维基百科,自由的百科全书](https://zh.wikipedia.org/wiki/環形緩衝區)

#### 5.1.4 归一化处理`Normalize`

将音频信号归一化到特定的范围(默认最大值为1),以标准化数据幅度.

#### 5.1.5 低通滤波器`LowPassFilter`

实现低通滤波器,用于去除音频信号中高频噪声.

>**低通滤波器**(Low-pass filter)容许低频信号通过,但减弱(或减少)频率高于截止频率的信号的通过.对于不同滤波器而言,每个频率的信号的减弱程度不同.当使用在音频应用时,它有时被称为**高频剪切滤波器**,或**高音消除滤波器**.
>
>具体参见 [低通滤波器 - 维基百科,自由的百科全书](https://zh.wikipedia.org/wiki/低通滤波器)

低通滤波器基于**卷积操作**和**窗函数法**进行实现.

**卷积操作**

滤波是通过将原始信号与一个滤波器核(或权重函数)进行卷积运算完成的: 

$$
y[i] = \sum_{j=0}^{n-1} x[i-j] \cdot b[j]
$$

其中: 

- $y[i]$ : 滤波后信号在第 $i$ 点的值.
- $x[i-j]$ : 输入信号对应的点.
- $b[j]$ : 滤波器的系数(也称为卷积核).

**窗函数法**

使用窗函数法构造滤波器系数 `b`.低通滤波器的理想系数基于 **Sinc 函数**: 

$$
\text{Sinc}(x) = \frac{\sin(\pi x)}{\pi x}
$$

但理想滤波器系数是无限长的,为了实际应用,需要使用窗函数如矩形窗对其截断,在有限长度 $ n $ 的范围内,计算低通滤波器的系数: 

$$
b[i] = 2 \cdot f_c \cdot \frac{\sin(2\pi f_c x)}{2\pi f_c x}, \quad x = i - \frac{n-1}{2}
$$

- $f_c$ : 归一化的截止频率(范围为0到0.5,表示相对于采样率的一半).
- $n$ : 滤波器核的长度(根据频率范围自动调整).

通过归一化使滤波器满足能量守恒的条件.

#### 5.1.6 降采样`DownSample`

对信号进行降采样,将高采样率数据转换为目标采样率.

**整比例降采样**(`DownSample1`)

整比例降采样直接选择输入信号中等间隔的点.假设采样率为 $f_s$ ,目标采样率为 $f_t$ ,采样率比 $R = \frac{f_s}{f_t}$ ,则输出信号的第 $i$ 个点为: 
$$
y[i] = x[i \cdot R]
$$

其中 $i$ 是输出信号的索引.

**非整比例降采样**(`DownSample2`)

非整比例降采样需要对输入信号进行插值.输出信号点的索引不再是整数,而是浮点数 $f_{\text{index}}$ .插值计算过程包括以下步骤: 

1. 计算目标点的浮点索引: 

$$
f_{\text{index}} = j \cdot \frac{f_s}{f_t}, \quad j = 0, 1, \ldots, N-1
$$

其中 $j$ 是目标采样率下的索引, $N$ 是输出信号长度.

2. 线性插值: 

对于浮点索引 $f_{\text{index}}$,找到最近的两个整数点 $i_0 = \lfloor f_{\text{index}} \rfloor$ 和 $i_1 = i_0 + 1$ ,计算: 

$$
y[j] = (1 - t) \cdot x[i_0] + t \cdot x[i_1]
$$

其中: $t = f_{\text{index}} - i_0$ 是插值因子. $x[i_0], x[i_1]$ 是输入信号在索引 $i_0, i_1$ 的值.

#### 5.1.7 预加重处理`PreEmphasis`

应用预加重滤波器,提高高频部分的能量,用于语音增强和特征提取.

> 预加重是一种在发送端对输入信号高频分量进行补偿的信号处理方式.随着信号速率的增加,信号在传输过程中受损很大,为了在接收终端能得到比较好的信号波形,就需要对受损的信号进行补偿,预加重技术的思想就是在传输线的始端增强信号的高频成分,以补偿高频分量在传输过程中的过大衰减.而预加重对噪声并没有影响,因此有效地提高了输出信噪比.
>
> 理论已经证明,[鉴频器](https://baike.baidu.com/item/鉴频器/5869020?fromModule=lemma_inlink)的输出[噪声功率谱](https://baike.baidu.com/item/噪声功率谱/14723919?fromModule=lemma_inlink)按频率的平方规律增加.但是,许多实际的消息信号,例如语言,音乐等,它们的[功率谱](https://baike.baidu.com/item/功率谱/6463147?fromModule=lemma_inlink)随频率的增加而减小,其大部分能量集中在低频范围内.这就造成消息信号高频端的[信噪比](https://baike.baidu.com/item/信噪比/206685?fromModule=lemma_inlink)可能降到不能容许的程度.但是由于消息信号中较高频率分量的能量小,很少有足以产生最大[频偏](https://baike.baidu.com/item/频偏/6892574?fromModule=lemma_inlink)的幅度,因此产生最大频偏的信号幅度多数是由信号的低频分量引起.平均来说,幅度较小的[高频分量](https://baike.baidu.com/item/高频分量/8356966?fromModule=lemma_inlink)产生的频偏小得多.所以[调频](https://baike.baidu.com/item/调频/771661?fromModule=lemma_inlink)信号并没有充分占用给予它的带宽.因为[调频系统](https://baike.baidu.com/item/调频系统/3243077?fromModule=lemma_inlink)的传输带宽是由需要传送的消息信号([调制信号](https://baike.baidu.com/item/调制信号/10414468?fromModule=lemma_inlink))的最高有效频率和最大频偏决定的.然而,接收端输入的噪声频谱却占据了整个调频带宽.这就是说,在[鉴频器](https://baike.baidu.com/item/鉴频器/5869020?fromModule=lemma_inlink)输出端噪声功率谱在较高频率上已被加重了.
>
> 为了抵消这种不希望有的现象,在调频系统中人们普遍采用了一种叫做预加重和[去加重](https://baike.baidu.com/item/去加重/9028978?fromModule=lemma_inlink)措施,其中心思想是利用信号特性和噪声特性的差别来有效地对信号进行处理.即在噪声引入之前采用适当的网络(预加重网络),人为地加重(提升)发射机输入调制信号的高频分量.然后在接收机鉴频器的输出端,再进行相反的处理,即采用去加重网络把高频分量去加重,恢复原来的信号功率分布.在去加重过程中,同时也减小了噪声的高频分量,但是预加重对噪声并没有影响,因此有效地提高了输出[信噪比](https://baike.baidu.com/item/信噪比/206685?fromModule=lemma_inlink).
>
> 具体参见 [预加重_百度百科](https://baike.baidu.com/item/预加重/9293616)

预加重滤波器通过对当前信号值减去一定比例的前一信号值,构造出一种高通滤波的效果.其数学表达式为: 

$$
y[n] = x[n] - p \cdot x[n-1]
$$

其中: 
- $y[n]$ : 滤波后的输出信号.
- $x[n]$ : 输入信号的当前采样值.
- $p$: 预加重系数(通常取值在 $ 0.9 \sim 1.0 $ ).
- $x[n-1]$ : 输入信号的前一个采样值.

预加重滤波器本质上是一个简单的一阶差分高通滤波器.对于语音信号: 
1. 低频部分: 
   - $x[n]$ 和 $x[n-1]$ 的值相近,差值较小,被削弱.
2. 高频部分: 
   - $x[n]$ 和 $x[n-1]$ 差值较大,高频分量得到增强.

频率响应函数为: 

$$
H(f) = 1 - p \cdot e^{-j2\pi f}
$$

其幅频响应:

$$
|H(f)| = \sqrt{1 - 2p \cos(2\pi f) + p^2}
$$

- 当 $p$ 越接近 1,高频增强效果越显著.
- $f = 0$ 时,增益为 $1 - p$ ,低频被削弱.

预加重系数 $p$ 的选择对滤波效果有重要影响: 
- $p = 0.9 \sim 0.97$ 是常见的取值范围.
- $p$ 越接近 1,增强高频的效果越明显,但可能会导致信号失真.
- 根据应用场景(如安静语音或噪声环境语音)调整 $p$ 值.

#### 5.1.8 汉明窗`HammingWindow`

对信号施加汉明窗,用于减少信号分段时的频谱泄漏.

> **窗函数**(英语: window function)在[信号处理](https://zh.wikipedia.org/wiki/信号处理)中是指一种除在给定[区间](https://zh.wikipedia.org/wiki/区间)之外取值均为0的实[函数](https://zh.wikipedia.org/wiki/函数).譬如: 在给定区间内为[常数](https://zh.wikipedia.org/wiki/常数)而在区间外为0的窗函数被形象地称为**矩形窗**.
>
> 任何函数与窗函数之积仍为窗函数,所以相乘的结果就像透过窗口"看"其他函数一样.窗函数在[频谱](https://zh.wikipedia.org/wiki/頻譜)分析,[滤波器设计](https://zh.wikipedia.org/wiki/滤波器设计),波束形成,以及音频数据压缩(如在[Ogg Vorbis](https://zh.wikipedia.org/wiki/Ogg_Vorbis)音频格式中)等方面有广泛的应用.
>
> 从理论上可以得出函数 $cos⁡(ωt)$ 的[傅立叶变换](https://zh.wikipedia.org/wiki/傅立叶变换)除了在频率 $±ω$ 之外处处为 0.但是许多其它的函数或者波形数据并没有这样方便的闭式变换,或者是我们只对某一时间范围内的频谱数据感兴趣,在这种情况下,就需要对有限时间范围的波形进行傅立叶变换或者其它类似的变换.通常通过波形与一个窗函数的乘积来表示.但是,包括矩形窗在内的所有窗函数都会对待测频谱产生影响.
>
> 当输入波形是采样信号而非连续信号时,傅立叶分析通常对信号应用窗函数并用离散傅立叶变换.但是[离散傅里叶变换](https://zh.wikipedia.org/wiki/离散傅里叶变换)得到的频谱只是[离散时间傅里叶变换](https://zh.wikipedia.org/wiki/离散时间傅里叶变换)频谱的一个粗糙采样.上图是正弦信号应用矩形窗后傅立叶频谱的一部分.位于横轴0点位置的是正弦信号真实频谱,其余频谱均为谱泄漏.频率单位为"DFT bins"(DFT 量化单位)即这些整数值是DFT采样得到的频率.所以该图显示了这样一种情况,正弦信号的实际频率正好与DFT的采样频率一致,并且频谱的最大值通过采样得到.采样错过最大值时的测量误差被称为"扇形损失"(名称源于顶点的形状).但是这种状况下最有趣的是那些与实际频谱相一致的即值为零的那些点.这种情况下,DFT创造了没有泄露的假象.尽管不如本例这样,泄露是DFT中人为引入的也是普遍误解.但是既然任何窗函数都有泄露,那些表面上的不存在泄露才是人为造成的.
>
> 具体参见 [窗函数 - 维基百科,自由的百科全书](https://zh.wikipedia.org/wiki/窗函数)

**Hamming窗与Hann窗**

>$$
>w(n) = a_0 - (1 - a_0) \cdot \cos\left(\frac{2\pi n}{N-1}\right), \quad 0 \leq n \leq N-1
>$$
>
>当  $a_0=0.53836$,称作 **Hamming窗**；当  $a_0=0.5$ 则叫作 **Hann窗**.
>
>**Hann窗**
>
>$$
>w(n)=0.5(1-\cos(\frac{2\pi n}{N-1}))
>$$
>
>[Hann窗](https://zh.wikipedia.org/w/index.php?title=Hann窗&action=edit&redlink=1)有时也称为 "Hanning" 窗("汉宁窗"),以与 Hamming 窗的名称类似.但是这是不对的,因为这两个窗是分别根据 [Julius von Hann](https://zh.wikipedia.org/w/index.php?title=Julius_von_Hann&action=edit&redlink=1) 和 [Richard Hamming](https://zh.wikipedia.org/wiki/Richard_Hamming) 的名字命名的.
>
>Hann窗又称升余弦窗.Hann窗可以看作是3个矩形时间窗的频谱之和,或者说是 3个 $sinc(t)$ 型函数之和,而括号中的两项相对于第一个谱窗向左,右各移动了 $π/T$ ,从而使旁瓣互相抵消,消去高频干扰和漏能.
>
>从减小泄漏观点出发,Hann窗优于矩形窗.但Hann窗主瓣加宽,相当于分析带宽加宽,频率分辨力下降.
>
>**Hamming窗**
>
>$$
>w(n) = 0.53836 - 0.46164 \cdot \cos\left(\frac{2\pi n}{N-1}\right)
>$$
>
>如果我们将  $a_0$ 设为接近 0.53836 的数值,或是更精确来说是 25/46,便会得到Hamming窗,而设定这个数值的用意,是在频率为 $5π/(N − 1)$ 处产生零交会处(zero-crossing),使原先Hann窗的第一个旁瓣(sidelobe)可以被大幅消除,产生只有Hann窗 1/5 高度的旁瓣.
>
>具体参见 [窗函数 - 维基百科,自由的百科全书](https://zh.wikipedia.org/wiki/窗函数)

#### 5.1.9 零填充`ZeroPadding`

在信号两端添加零,扩展信号长度,用于频谱分析等场景.

#### 5.1.10 快速傅里叶变换`FFT`

计算信号的频谱,用于分析信号在频域的分布.

>**快速傅里叶变换**(英语: **Fast Fourier Transform, FFT**),是快速计算序列的[离散傅里叶变换](https://zh.wikipedia.org/wiki/离散傅里叶变换)(DFT)或其逆变换的方法.[傅里叶分析](https://zh.wikipedia.org/wiki/傅里叶分析)将信号从原始域(通常是时间或空间)转换到[频域](https://zh.wikipedia.org/wiki/頻域)的表示或者逆过来转换.FFT会通过把[DFT矩阵](https://zh.wikipedia.org/wiki/離散傅里葉變換矩陣)[分解](https://zh.wikipedia.org/wiki/矩阵分解)为[稀疏](https://zh.wikipedia.org/wiki/稀疏矩阵)(大多为零)因子之积来快速计算此类变换.因此,它能够将计算DFT的[复杂度](https://zh.wikipedia.org/wiki/計算複雜性理論)从只用DFT定义计算需要的 $O(n^2)$ ,降低到 $O(n\log ⁡n)$ ,其中 $n$ 为数据大小.
>
>具体参见 [快速傅里叶变换 - 维基百科,自由的百科全书](https://zh.wikipedia.org/wiki/快速傅里叶变换)

#### 5.1.11 Mel滤波器组`MelFilterBank`

将频谱转换为Mel尺度频谱,用于语音信号的MFCC特征提取.

**Mel尺度变换(从Hz到Mel)**

Mel尺度是一种对频率的非线性变换,它模仿了人耳对不同频率的敏感度.人耳对低频信号的变化更为敏感,而对高频信号的变化则不太敏感.Mel尺度变换使得频率的间隔在低频部分较小,在高频部分较大.

Mel尺度与Hz之间的关系可以通过以下公式表示: 

$$
\text{Mel}(f) = 2595 \cdot \log_{10} \left( 1 + \frac{f}{700} \right)
$$

其中: 
- $f$ 是以赫兹(Hz)为单位的频率；
- $\text{Mel}(f)$ 是对应的Mel频率.

为了从Mel频率转换回Hz频率,使用逆公式: 

$$
f = 700 \cdot \left( 10^{\frac{\text{Mel}(f)}{2595}} - 1 \right)
$$

在代码中,`ToMel` 和 `ToHz` 函数分别执行这两种转换,分别是 **Hz -> Mel** 和 **Mel -> Hz** 的转换.

**Mel频率滤波器组(Mel Filter Bank)**

Mel频率滤波器组用于将原始频谱(通常是FFT频谱)转换到Mel尺度的频谱.滤波器组由多个三角形滤波器组成,每个滤波器对应Mel尺度上的一个频带. `MelFilterBank` 函数通过以下步骤实现了Mel滤波器组的计算: 

- 频率范围设置: 
  - `fMax = sampleRate / 2` 是Nyquist频率,即信号的最大频率.
  - `melMax = ToMel(fMax)` 将Nyquist频率转换为Mel频率.
  
- 频率步长: 
  - `df = fMax / nMax` 是FFT结果中频率的间隔,其中 `nMax = len / 2` 是FFT的长度(假设是对称的,因此只有一半的频谱是有用的).

- Mel频率步长: 
  - `dMel = melMax / (melDiv + 1)` 计算每个Mel滤波器带宽的宽度,其中 `melDiv` 是Mel滤波器的数量.

**滤波器的实现**

对于每个Mel滤波器,它的频率范围由三个值确定: 开始频率( $f_{{Begin}}$ ),中心频率( $f_{Center}$ ) 和结束频率( $f_{End}$ ),这些频率是Mel尺度上的值.然后这些值会被转换回Hz频率.每个滤波器的形状是一个三角形,并且它的响应是随着频率的变化逐渐增大然后再减小.具体来说: 

- 当频率低于滤波器的中心频率时,滤波器的增益随着频率的增加而线性增加；
- 当频率高于滤波器的中心频率时,增益随着频率的增加而线性减小.

对于每个Mel滤波器,通过以下步骤来计算其权重: 

1. 计算滤波器的增益: 
   - 如果频率小于中心频率,增益线性增加:  $(f - f_{{Begin}}) / (f_{Center} - f_{Begin})$
   - 如果频率大于中心频率,增益线性减小:  $(f_{End} - f) / (f_{End} - f_{Center})$

2. 归一化: 
   - 为了保持每个滤波器的总能量不变,增益会被标准化: $\frac{1}{0.5 \cdot (f_{End} - f_{{Begin}})}$

3. 加权频谱: 
   - 对于每个滤波器,滤波器的权重与原始频谱中的对应频率相乘,然后累加得到Mel频率谱.

最终,通过将所有滤波器的加权结果累加,得到每个Mel滤波器的输出,作为Mel频谱的最终值.

#### 5.1.12 功率转dB`PowerToDb`

将信号功率转换为分贝(dB)表示,用于更直观的表示信号强度.

#### 5.1.13 Mel-Hz转换`ToMel` 和 `ToHz`

实现频率和Mel尺度之间的互相转换,用于Mel滤波器的设计.

#### 5.1.14 离散余弦变换`DCT`

实现离散余弦变换,用于从Mel频谱生成MFCC特征.

>**离散余弦变换**(英语: **discrete cosine transform, DCT**)是与[傅里叶变换](https://zh.wikipedia.org/wiki/傅里叶变换)相关的一种变换,类似于[离散傅里叶变换](https://zh.wikipedia.org/wiki/离散傅里叶变换),但是只使用[实数](https://zh.wikipedia.org/wiki/实数).离散余弦变换相当于一个长度大概是它两倍的离散傅里叶变换,这个离散傅里叶变换是对一个实[偶函数](https://zh.wikipedia.org/wiki/偶函数)进行的(因为一个实偶函数的傅里叶变换仍然是一个实偶函数),在有些变形里面需要将输入或者输出的位置移动半个单位(DCT有8种标准类型,其中4种是常见的).
>
>离散余弦变换,尤其是它的第二种类型,经常被[信号处理](https://zh.wikipedia.org/wiki/信号处理)和[图像处理](https://zh.wikipedia.org/wiki/图像处理)使用,用于对[信号](https://zh.wikipedia.org/wiki/信号)和[图像](https://zh.wikipedia.org/wiki/图像)进行[有损数据压缩](https://zh.wikipedia.org/wiki/有损数据压缩).这是由于离散余弦变换具有很强的"能量集中"特性: 大多数的信号信息(包括声音和图像)往往集中在离散余弦变换后的低频部分,而且当信号具有接近[马尔可夫过程](https://zh.wikipedia.org/wiki/马尔可夫过程)的统计特性时,离散余弦变换的去相关性接近于[K-L变换](https://zh.wikipedia.org/wiki/K-L变换)(Karhunen-Loève变换——它具有最优的去相关性)的性能.
>
>具体参见 [离散余弦变换 - 维基百科,自由的百科全书](https://zh.wikipedia.org/wiki/离散余弦变换)

#### 5.1.15 范数计算`Norm`

计算信号的二范数,用于量化信号的整体能量.

### 5.2 公共常量 Common

静态类`Common` 提供了一些常量,定义了音频处理和语音同步相关的默认值.

- `AssetName`: 资源名称,用于标识该系统或模块( `rinaLipSync`).
- `DefaultMinVolume` 和 `DefaultMaxVolume`: 音量的默认范围,用于音量归一化或特定阈值的处理.
- `MfccMinValue` 和 `MfccMaxValue`: MFCC的取值范围,用于特征值标准化或处理.

### 5.3 语音同步信息结构 LipSyncInfo
结构体`LipSyncInfo` 用于存储语音同步的中间结果和相关信息.

- `phoneme`: 当前检测到的元音(语音单元).
- `volume`: 归一化后的音量值,用于控制动画或模型的嘴部运动.
- `rawVolume`: 原始音量值,未经过处理的音频输入数据.
- `phonemeRatios`: 存储每个元音的匹配度比例,用于决定最终的元音输出.

### 5.4 口型同步事件 LipSyncUpdateEvent

Unity序列化事件类`LipSyncUpdateEvent`用于触发和处理 `LipSyncInfo` 的更新,主要用于实现松耦合,将语音同步结果传递到其他系统.

### 5.5 音频读取事件 AudioFilterReadEvent

Unity 序列化事件类`AudioFilterReadEvent`用于处理音频数据的实时读取.

- `float[]`: 音频缓冲区,存储当前帧的音频数据.
- `int`: 缓冲区的长度或与音频帧相关的索引.

### 5.6 更新方法枚举 UpdateMethod
枚举`UpdateMethod` 定义语音同步信息更新的触发机制.
- `LateUpdate`: 在每帧结束时更新.
- `Update`: 在每帧的常规更新阶段触发.
- `FixedUpdate`: 在物理更新周期中触发.
- `LipSyncUpdateEvent`: 由事件触发更新.
- `External`: 由外部系统控制更新.

### 5.7 比较方法枚举 CompareMethod
枚举`CompareMethod` 定义元音匹配算法的比较方式.
- `L1Norm`: 基于曼哈顿距离(绝对值差)的匹配方法.
- `L2Norm`: 基于欧几里得距离的匹配方法.
- `CosineSimilarity`: 基于余弦相似度的匹配方法,用于判断两个向量的方向相似性.

### 5.8 口型同步任务系统 LipSyncJob

该任务系统为`Unity.Jobs.IJob`接口的实现,主要功能是基于输入的音频数据,提取特征并匹配元音,确定元音对应的权重以及主要元音的索引.

#### 5.8.1 成员变量
- 输入: 
  - `input`: 输入的原始音频信号.
  - `startIndex`: 音频缓冲区的起始索引,用于处理循环缓冲区.
  - `outputSampleRate` 和 `targetSampleRate`: 输出和目标采样率,用于降采样处理.
  - `melFilterBankChannels`: Mel滤波器组的通道数,用于频谱到Mel频谱的转换.
  - `compareMethod`: 元音匹配的比较方法(L1,L2或余弦相似度).
  - `means` 和 `standardDeviations`: 均值和标准差,用于标准化MFCC特征.
  - `phonemes`: 元音参考数据,存储每个元音的MFCC特征.

- 输出: 
  - `mfcc`: 提取的MFCC特征.
  - `scores`: 每个元音的匹配分数.
  - `info`: 包含音量和主要元音索引的信息.
  - (调试模式下)`debugData`,`debugSpectrum` 等数据用于输出中间处理结果.

#### 5.8.2 主要处理步骤
1. 音频预处理: 
   - 通过`Algorithm.GetRMSVolume`计算音频信号的整体音量.
   - 使用循环缓冲区重排音频数据,并应用低通滤波器去除高频噪声.
   - 将音频降采样到目标采样率,减小计算负担.
   - 应用预加重滤波器强化高频信号.
   - 对音频施加汉明窗减少频谱泄露,并归一化数据.

2. 特征提取: 
   - 使用FFT(快速傅里叶变换)计算频谱.
   - 应用Mel滤波器组将频谱转换为Mel尺度.
   - 将Mel频谱转换为dB(分贝)单位.
   - 通过DCT(离散余弦变换)提取MFCC特征.

3. 元音匹配: 计算每个元音的匹配分数,支持三种匹配方法: 
   - `L1Norm`: 使用绝对值距离计算分数.
   - `L2Norm`: 使用欧几里得距离计算分数.
   - `CosineSimilarity`: 使用余弦相似度计算分数.
   
4. 元音检测: 从匹配分数中选出得分最高的元音,确定主要元音索引.

#### 5.8.3 匹配分数计算
- `CalcL1NormScore`:  计算L1距离(曼哈顿距离),表示MFCC与元音特征之间的绝对值差异.
- `CalcL2NormScore`:  计算L2距离(欧几里得距离),表示MFCC与元音特征的平方差累积.
- `CalcCosineSimilarityScore`:  计算余弦相似度,表示MFCC与元音特征的方向相似性.

### 5.9 MFCC校准数据 MfccCalibrationData

结构体`MfccCalibrationData`主体为一个包含 12 个浮点数的数组,用于表示单个 MFCC 校准数据.提供索引器 (`this[int i]`) 和数组长度 (`Length`) 的访问.

### 5.10 MFCC数据 MfccData

类型`MfccData`用于存储与某个元音相关的 MFCC 数据和其校准信息.包含以下功能: 

- 动态分配和释放内存:  使用 `NativeArray` 管理原生内存(持久化分配).
- 校准数据管理: 
  - `AddCalibrationData`: 添加一组新的 MFCC 校准数据.
  - `RemoveOldCalibrationData`: 移除过多的校准数据,保留一定数量的历史数据.
- 平均值更新: 
  - `UpdateNativeArray`: 基于历史校准数据更新平均值(将结果存储到 `mfccNativeArray`).

### 5.11 识别模型预设配置文件 Profile

类型 `Profile`继承自`UnityEngine.ScriptableObject`,用于保存和管理整个口型同步识别模型的相关配置和数据.

#### 5.11.1 配置选项
该类型提供了一些可以通过 Unity Inspector 面板直接配置的选项: 
- `mfccNum`: MFCC 系数的数量(通常是 12).
- `mfccDataCount`: 用于计算平均值的历史校准数据数量.
- `melFilterBankChannels`: Mel 滤波器组的通道数量.
- `targetSampleRate`: 目标采样率(降采样后).
- `sampleCount`: 降采样后的样本数量.
- `useStandardization`: 是否标准化 MFCC 系数.
- `compareMethod`: 比较元音匹配的方式(L1,L2 或余弦相似度).

#### 5.11.2 数据管理功能
- 数据添加/删除: 
  - `AddMfcc`: 为新元音添加数据.
  - `RemoveMfcc`: 移除指定索引的元音数据.
- 数据更新: 
  - `UpdateMfcc`: 更新指定元音的 MFCC 数据,支持校准模式.
- 数据导入/导出: 
  - `Export` 和 `Import`: 支持将配置导出为 JSON 文件,或从文件中加载.
- 计算平均值和标准差: 
  - `UpdateMeansAndStandardization`: 更新所有元音的均值和标准差.
  - `UpdateMeans` 和 `UpdateStandardizations`: 分别计算均值和标准差.
- 计算最大/最小值: 
  - `CalcMinMax`: 计算所有元音数据的最小值和最大值.

### 5.12 麦克风设备 MicDevice
结构体`MicDevice` 用于存储单个麦克风设备的信息

- `name`: 设备名称.
- `index`: 设备在系统中麦克风设备列表中的索引.
- `minFreq`: 设备支持的最低采样频率.
- `maxFreq`: 设备支持的最高采样频率.

### 5.13 麦克风工具 MicUtil
工具类`MicUtil` 提供了`GetDeviceList` 方法: 

- 遍历系统中所有的麦克风设备.
- 获取每个设备的名称和支持的频率范围.
- 返回一个包含所有麦克风设备信息的 `List<MicDevice>`.

## 6. 组件 Components

该部分调用工具模块,附着在组件上来实现具体的口型同步功能,根路径位于`Assets/Scripts/Components`.

### 6.1 音频源组件 RinaLipSyncAudioSource

`RinaLipSyncAudioSource` 类继承自 `MonoBehaviour`,依赖组件 `AudioSource`.

#### 6.1.1 成员

成员变量为自定义事件 `onAudioFilterRead`,类型为 `AudioFilterReadEvent`.

成员函数为: `OnAudioFilterRead` 

- 参数: 
  - `input`: 包含当前帧的音频样本数据.
  - `channels`: 音频的通道数(例如单声道为1,立体声为2).
- 工作流程: 
  - 在 `AudioSource` 处理音频的每一帧时调用.
  - 将音频数据 `input` 和通道信息 `channels` 转发给 `onAudioFilterRead` 事件的订阅者.

#### 6.1.2 工作流程
1. 当一个 `AudioSource` 播放音频时,Unity 会调用 `OnAudioFilterRead` 方法,并传递当前帧的音频数据.
2. `RinaLipSyncAudioSource` 将捕获的音频数据打包为事件参数,触发 `onAudioFilterRead` 事件.
3. 其他脚本或组件可以通过订阅 `onAudioFilterRead`,实时处理音频数据.

### 6.2 麦克风组件 RinaLipSyncMicrophone

`RinaLipSyncMicrophone`类继承自 `MonoBehaviour`,用于从麦克风捕获音频数据并通过 `AudioSource` 播放,同时提供麦克风管理和音频同步的功能.

#### 6.2.1 功能设计

- 麦克风管理

    - 动态获取麦克风设备: 使用 `MicUtil.GetDeviceList` 获取系统中的麦克风设备列表,并根据指定的索引选择设备.

    - 实时切换设备: 允许在运行时更改当前麦克风设备,并根据需要重新初始化录音.


- 音频捕获与同步

    - 麦克风音频流捕获: 使用 Unity 的 `Microphone.Start` 开始录音,并将录制的数据存储为 `AudioClip`.

    - 音频同步校正: 检测麦克风和 `AudioSource` 播放之间的延迟 (`latency`),并在延迟超出阈值时重新同步.


- 状态管理:通过一系列布尔标志管理麦克风和音频源的状态: 

    - `isRecording`: 是否正在录音.

    - `isReady`: 麦克风是否已初始化.

    - `isStartRequested` 和 `isStopRequested`: 控制录音的启动和停止请求.


- 音频数据处理
    - 提供功能从麦克风捕获的音频创建新的 `AudioClip`,便于后续保存或处理.

#### 6.2.2 成员属性

- `index`: 指定使用的麦克风设备索引.
- `latencyTolerance` 和 `bufferTime`: 用于设置同步的时间阈值和缓冲时间,确保音频流的平滑播放.
- `source` 和 `clip`: 与 `AudioSource` 关联的音频源和音频剪辑.

#### 6.2.3 成员函数

- `StartRecord` 和 `StopRecord`
   - 控制麦克风录音的启动和停止,通过设置请求标志触发实际操作.
   
- `StartRecordInternal`
   - 实际启动麦克风录音,并将录音的 `AudioClip` 设置为 `AudioSource` 的音频剪辑.

- `StopRecordInternal`
   - 停止麦克风录音,停止 `AudioSource` 的播放.

- `UpdateLatencyCheck`
   - 检查麦克风和 `AudioSource` 的延迟是否超出阈值.
   - 如果延迟过大,尝试重新同步或重新启动录音.

- `StopRecordAndCreateAudioClip`
   - 停止录音并创建一个新的 `AudioClip`,将当前捕获的音频数据存储下来,便于后续处理.

### 6.3 口型同步核心组件 RinaLipSync

`RinaLipSync`类继承自 `MonoBehaviour`,是整个口型同步系统的调度中心.

#### 6.3.1 功能设计

- 音频数据捕获: 
  - 从音频源(`RinaLipSyncAudioSource`)接收音频数据.
  - 动态调整缓冲区并管理音频输入.
  
- 特征提取与同步: 
  - 使用 `LipSyncJob` 进行高效的特征提取,包括 MFCC,元音评分等.
  - 将结果计算为 `LipSyncInfo`,包括元音,音量和元音比例.

- 实时校准: 
  - 根据请求更新元音校准数据,使模型能够动态调整和优化.

- 事件驱动: 
  - 使用 `LipSyncUpdateEvent` 将同步结果传递给外部系统.

#### 6.3.2 成员属性
- `profile`: `Profile` 对象,包含音频处理的配置信息(如采样率,MFCC 参数,元音库等).
- `onLipSyncUpdate`: 一个事件,提供给外部系统监听语音同步的实时结果.
- `_rawInputData` 和 `_inputData`: 缓冲区,用于存储音频数据.
- `_mfcc` 和 `_scores`: 存储实时计算的 MFCC 特征和元音评分.
- `_ratios`: 字典,存储每个元音的比例,用于生成口型同步的最终结果.

#### 6.3 成员方法

- 数据捕获

    - `OnDataReceived(float[] input, int channels)`: 
      - 从音频源接收输入数据,存储到 `_rawInputData` 中.
      - 根据 `outputSoundGain` 调整音频增益.
    - `OnAudioFilterRead(float[] input, int channels)`: Unity 的音频回调,用于捕获音频数据流.


- 数据处理

    - `ScheduleJob()`: 
      
      - 调用 `LipSyncJob`,在音频数据上执行特征提取,包括 FFT,MFCC,Mel 滤波等操作.
      - 使用 Unity 的 `Job System` 进行高性能并行计算.
      
      - `UpdateResult()`: 
        - 处理 `LipSyncJob` 的结果,计算主要元音和元音比例.
        - 标准化音量数据,将其映射到 `[0, 1]` 范围.
    
- `InvokeCallback()`: 触发 `onLipSyncUpdate` 事件,将处理结果回调给监听者.


- 校准

    - `RequestCalibration(int index)`: 添加校准请求,指定需要校准的元音索引.

    - `UpdateCalibration()`: 根据校准请求更新元音的 MFCC 数据,以动态调整模型的特征匹配.


- 内存管理
    - `AllocateBuffers()` 和 `DisposeBuffers()`: 动态分配和释放音频缓冲区以及特征提取的中间存储数据.


- 调试与编辑器支持

    - 在调试模式下,支持更多的中间数据(如频谱,Mel 滤波结果)的可视化.

    - 提供 `OnBakeStart` 和 `OnBakeEnd` 方法,用于编辑器模式下的批量处理.


### 6.4 表情管理模块组件 RinaLipSyncFaceManager

`RinaLipSyncFaceManager`类继承自 `MonoBehaviour`,提供了一个回调函数给`RinaLipSync`在口型改变时触发.以便将表情同步到璃奈板硬件上.

#### 6.4.1 功能设计

- 元音驱动表情更新: 根据语音同步系统传递的元音和音量数据,确定当前的表情(口型).
- 表情状态管理: 记录和统计元音历史,稳定元音识别结果,避免频繁切换.
- 通过 UDP 通信控制表情设备: 通过一个 `UdpServer` 将表情数据发送到硬件设备.

#### 6.4.2 成员属性
- `updateMethod`: 表示更新的触发方式,支持 `Update` 和 `LipSyncUpdateEvent` 等选项.
- `volume` 和 `minVolume`: 当前音量及音量的最低阈值,低于此值时嘴巴保持关闭状态.
- `phonemeHistory`: 存储元音历史,用于稳定元音识别结果.
- `faceDict`: 字典,存储元音与对应表情的映射.
- `phonemeCountTable`: 统计元音历史中各元音出现的次数.

#### 6.4.3 成员方法

- `OnLipSyncUpdate(LipSyncInfo info)`: 
  - 接收语音同步系统传递的元音信息,并触发后续更新流程.
  - 如果更新方法是 `LipSyncUpdateEvent`,直接更新口型.

- `UpdateLipSync()`: 
  - 包括音量更新(`UpdateVolume`)和元音更新(`UpdateVowels`).
  - 元音更新基于元音历史统计当前的主要元音,避免识别抖动.

- `Apply()`: 
  - 根据当前元音(`phoneme`)和音量(`volume`),决定是否更新表情.
  - 如果嘴巴需要关闭,切换到默认表情(`"N"`).
  - 如果需要更新表情,通过 `UdpServer` 将表情数据发送给硬件.

#### 6.4.4 方法逻辑设计

- 元音历史统计: 在 `UpdateVowels()` 方法中: 
    1. 将元音记录到 `phonemeHistory`.
    1. 移除过旧的记录,保证历史长度不超过设定的最短持续时间.
    1. 统计 `phonemeHistory` 中每个元音的出现次数,取出现次数最多的元音作为当前元音.


- 表情更新逻辑: 在 `Apply()` 方法中: 
    1. 如果音量低于 `minVolume`: 
       - 关闭嘴巴(`"N"` 表情).
       - 通过 `UdpServer` 更新设备.
    2. 如果音量足够大且元音发生变化: 
        - 更新对应的口型表情(`faceDict`).
        - 将表情数据通过 `UdpServer` 发送到设备.